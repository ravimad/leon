\newcommand{\real}{\mathbb{R}}
\newcommand{\lmige}{\succcurlyeq}

\section{Survey of the Selected Papers}

\subsection{Program invariance and termination using Lagrangian Relaxation and Semidefinite Programming} \label{sec:paper1}

\cite{cousot:VMCAI05} proposes an approach for inferring polynomial invariants that 
to a user-defined \emph{template} which is a polynomial with unknown coefficients.
The technique is proposed for semi-algebraic programs which are numerical programs with real valued variables 
and iterative constructs of the form \texttt{while B do C} where B is a boolean condition 
and C is an imperative command. Figure~\ref{fig:SAprogram} shows a semialgebraic program that computes the least factorial greater than or equal to a given N.
%
\begin{figure}
\begin{myprogram}
\\
\pnl \>  n = 0 \\
\pnl \> f = 1 \\
\pnl \> while(f <= N) \{ \\
\pnl \> \> n = n+1 \\
\pnl \> \> f = n* f \\
\pnl \> \}
\end{myprogram}
\caption{A program computing the least factorial greater than or equal to a given N.} \label{fig:SAprogram}
\end{figure}
%
Assume that the (relational) semantics of an iteration is given by a formula of the form
$\bigwedge \limits_{k=1}^{n} (\sigma_k(x,x') \ge 0)$ where, $x$ and $x'$ are the vectors of
variables representing the values of $m$ program variables before and after an iteration, respectively 
and $\sigma_k : \real^m \times \real^m \mapsto \real$ is a polynomial over $x$ and $x'$. 
In other words, it is assumed that the relational semantics of each
iteration can be expressed as a conjunction of polynomial positivity constraints.
For the program shown in Figure~\ref{fig:SAprogram} the relational semantics of the 
loop is given by $N-f \ge 0 \wedge n' -n -1 = 0 \wedge f' - n'.f = 0$ (where 
$A = 0$ is a short hand for $A \ge 0 \wedge -A \ge 0$).

An inductive invariant of a loop is another polynomial inequality $I(x) \ge 0$ 
that satisfies the following inductiveness constraints:
%
\begin{align}
& \forall x. P(x) \ge 0 \Rightarrow I(x) \ge 0 \\
& \forall x,x'. I(x) \ge 0 \wedge \bigwedge_k (\sigma_k(x,x') \ge 0) \Rightarrow  I(x') \ge 0
\end{align}
%
where $P(x) \ge 0$ is the precondition.
To prove that a property $S(x) \ge 0$ is an invariant of the loop we need to find an $I(x)$ such that
$\forall x. I(x) \ge 0 \Rightarrow S(x) \ge 0$.
Assume that we are interested only in solutions of $I(x)$ having the form $I_a(x)$ which is a polynomial with unknown coefficients given by a vector $a$. 
For example, $I_a(x) = a (x \; 1)^T$ represents all linear (or affine) invariants, 
$I_a(x) = (x \; 1) a (x \; 1)^T$, where $a$ is a symmetric matrix of unknown 
coefficients, represents all quadratic invariants  and so on. 
Using this assumption we can rewrite the above constraints as follows:
%
\begin{align}
& \nonumber \exists a \in \real^p:  \\
& \forall x. P(x) \ge 0 \Rightarrow I_a(x) \ge 0  \label{eq:template1}\\
& \forall x,x'. I_a(x) \ge 0  \wedge \bigwedge_k (\sigma_k(x,x') \ge 0) \Rightarrow  I_a(x') \ge 0 \label{eq:template2}
\end{align}
%
Hence,  the problem essentially reduces to finding a vector $a$ that satisfies
the above constraints.

The paper proposes to use \emph{Langrangian Relaxation} method to solve for $a$ in the above constraints. The method states that to prove 
$\forall v. \bigwedge \limits_{k=1}^{n} \sigma_k(v) \ge 0 \Rightarrow \sigma_0(v) \ge 0$ it suffices to prove that 
%
\begin{align}
\exists (\lambda_1 \cdots \lambda_n) \in (\real^+)^n. \; \forall v. \; \left( \sigma_0(v) -
\sum \limits_{k=1}^{n} \lambda_k. \sigma_k(v) \right) \ge 0 \label{eq:lagrange}
\end{align}
%
By Lagrangian relaxation, the constraints~\ref{eq:template1} and \ref{eq:template2}
can be reduced to the following:
%
\begin{align}
& \nonumber \exists a \in \real^p, \exists \mu \in \real^+, \exists (\lambda_0 \cdots \lambda_n) \in (\real^+)^{n+1}  : \\
&\forall x. I_a(x) - \mu.P(x)  \ge 0  \label{eq:inv1}\\
&\forall x,x'. \left( I_a(x') - \lambda_0.I_a(x) - \sum \limits_{k=1}^{n} \lambda_k. \sigma_k(x,x') \right)  \ge 0 \label{eq:inv2}
\end{align}
%
Lagrangian relaxation is in general incomplete i.e, it is not a necessary condition.
However, when the relational semantics is linear i.e, for all $k$, 
$\sigma_k(v)$ is linear then it is complete by \emph{Farkas' lemma}.
In fact, as discussed in some of the other related works \cite{ssriram:CAV03,ssriram:SAS04}, in the linear case, the constraint~\ref{eq:lagrange} 
can be further reduced to a set of quadratic constraints on the 
coefficients of $\sigma_k$ using \emph{Farkas' Lemma}. 
By solving for the unknown coefficients (obtained from the template $I_a$) in the
quadratic constraints one can infer an inductive invariant.
However, this is valid only for the linear case. We will shortly discuss
the solution proposed in the paper for solving constraints~\ref{eq:inv1} and \ref{eq:inv2}.

The paper also considers a related problem of proving termination of a program
and shows that it can also be reduced to finding a solution to constraints 
similar to \ref{eq:inv1} and \ref{eq:inv2}. A standard way of proving that 
a loop always terminates is to discover a function (called \emph{ranking function}) whose value strictly decreases at every loop iteration and remains positive across all iterations.
Furthermore, the decrease of the ranking function has to be bounded from below to avoid zeno phenomenon.
Formally, a function $r: \real^m \mapsto \real$ is a ranking function 
if it satisfies the following constraints:
%
\begin{align*}
& \exists \delta \in \real:  \qquad \delta > 0 \\
& \forall x. \; I(x) \ge 0 \Rightarrow r(x) \ge 0 \\
& \forall x,x'. I(x) \ge 0  \wedge \bigwedge_k \sigma_k(x,x') \ge 0 \Rightarrow  
(r(x) - r(x') - \delta) \ge 0
\end{align*}
%
where $I(x)$ is a loop invariant which is assumed to be already inferred 
or given by the user. 
In plain words, the constraints enforce that $r(x) \ge 0$ is a loop invariant 
(note that it is implied by a known invariant) and that it strictly decreases by atleast $\delta$ in each iteration.

As in the case of invariants, assume that the ranking function is also given by
a polynomial template $r_a(x)$ with unknown coefficients $a$. By lagrangian
relaxation, the ranking function constraints can be reduced to the following form:
%
\begin{align}
& \nonumber \exists \delta \in R, \exists a \in \real^p, \exists \mu \in \real^+, \exists (\lambda_0 \cdots \lambda_n) \in (\real^+)^{n+1} : \\
& \delta > 0 \label{eq:rank1}\\
& \forall x. \; r_a(x) - \mu.I(x)  \ge 0 \label{eq:rank2}\\
& \forall x,x'. \left( r_a(x) - r_a(x') - \delta - \lambda_0.I(x) - \sum \limits_{k=1}^{n} \lambda_k. \sigma_k(x,x') \right) \ge 0 \label{eq:rank3}
\end{align}

If $r_a(x)$, $I(x)$ and $\sigma(x,x')$ are conjunctions of quadratic polynomials 
of the form $\bigwedge_k (x \; x' \; 1) M_k (x \; x' \; 1)^T$ then constraints~\ref{eq:rank1}--\ref{eq:rank3} become \emph{Linear Matrix Inequalities} (LMIs). A LMI is of the form  $M(u) \lmige 0$, where $u \in \real^l$. 
$M(u) \lmige 0$ is defined as \emph{positive semidefiniteness} which is 
given by $\forall X \in \real^n: X M(u) X^T \ge 0$, where 
$M(u)$ is of the form $M_0 + \sum \limits_{k=1}^{l} u_k. M_k$ with
symmetric matrices $M_k = M_k^T$.
Finding a solution to the constraints \ref{eq:rank1}--\ref{eq:rank3}
reduces to a \emph{Semidefinite programming feasibility problem} which 
is to find a solution to a set of linear
matrix inequalities: $\exists u \in \real^l. \; M(x) \lmige 0$.
The paper proposes to use semidefinite programming solvers 
to find a solution to the ranking function constraints.

For example, consider the program shown in Figure~\ref{fig:SAprogram}.
Say we are given a loop invariant $n \ge 0 \wedge (f-1) \ge 0$.
Say $r_a$ is given by the template $(a \; b \; c \; d)(n \; f \; N \; 1)^T$. 
Consider the constraint~\ref{eq:rank2}. Since, the given invariant 
is a conjunction of two inequalities Constraint~\ref{eq:rank2} should be modified as $r_a(x) - \mu_1.I_1(x)- \mu_2.I_2(x) \ge 0$. 
Substituting for $r_a$, $I_1$ and $I_2$ we get,
$((a- \mu_1) \; (b - \mu_2) \; c \; (d-\mu_2))(n \; f \; N \; 1)^T \ge 0$.
This could be expressed in the form $X M(u) X^T \ge 0$, where 
$X=(n \; f \; N \; 1)$, $u = (a \; b \; c \; d \; \mu_1 \; \mu_2)$, 
as shown below:
%
\begin{align*}
M(u) = 
\left( \begin{array}{cccc} 
0 & 0 & 0 & (a- \mu_1)/2 \\
0 & 0 & 0 & (b- \mu_2)/2 \\
0 & 0 & 0 & c/2 \\
(a- \mu_1)/2 & (b- \mu_2)/2 & c/2 & (d-\mu_2) 
\end{array} \right)
\end{align*}
%
The above matrix can be converted to the LMI form: 
$M_0 + a M_1 + b M_2 + c M_3 + d M_4 + \mu_1 M_5 + \mu_2 M_6$.
Similarly, the constraints~\ref{eq:rank3} can also be converted to a LMI.
Hence, for this example, the coefficients of the ranking function $a,b,c,d$
can be determined by semidefinite programming solvers.
One possible solution for the coefficients is $(-1 \; 1 \; 1 \; 0)$. However,
the actual solvers may produce less intuitive solution involving arbitrary real numbers.

Now lets refocus on the problem of inferring invariants by solving constraints~\ref{eq:inv1}--\ref{eq:inv2}. As before lets assume that
$I_a(x)$ and $\sigma(x,x')$ are conjunctions of quadratic polynomials 
of the form $\bigwedge_k (x \; x' \; 1) M_k (x \; x' \; 1)^T$.
Unlike the ranking function constraints, invariant constrains cannot be 
expressed as LMIs. This is because of the term $\lambda_0.I_a(x)$ occurring
in the constraint~\ref{eq:inv2}. In this case, both $\lambda_0$ and the 
coefficients in $I_a(x)$ are unknowns and hence $\lambda_0.I_a(x)$ would contain
multiplication of two unknowns. However, these can be expressed as \emph{bilinear matrix inequalities} (BMIs). A BMI has the form $M(u,u') \lmige 0$ where $M(u,u')$
is a bilinear matrix of the form: 
$M_0 + \sum \limits_{i=1}^{p} u_i.M_i + \sum \limits_{j=1}^{q} u'_j.M'_j + \sum \limits_{i=1}^{p} \sum \limits_{j=1}^{q} u_i.u'_j.M''_{ij}$,
where, $u \in \real^p$, $u' \in \real^q$ and $M'_j$,$M''_{ij}$ are symmetric matrices. BMI solvers can be used to solve a set of BMIs constraints  of the form $\exists u,u'. M(u.u') \lmige 0$. Thus, quadratic invariants can be solved using BMI solvers. It is to be noted that BMI solving is NP-hard. The paper proposes
to use BMI solvers for finding quadratic inductive invariants belonging to a given template.

The paper also discusses an extension that could be used to solve constraints obtained by lagrangian relaxation of higher-degree polynomials (with degree more than 2). Consider the constraints \ref{eq:rank1}--\ref{eq:rank3}. Let the highest degree of all the polynomials in the constraints be $m$. Let $(x \; x') \in \real^n$ i.e, let there be $n$ variables. The approach works by converting the constraints to a set of LMIs of dimension ${ n+ d \choose d}$, where $d = m/2$, which is the number of monomials in $n$ variables with degree atmost $d$. The conversion is lossy i.e, incomplete. We elide the details of the extension for conciseness.

Consider the list reversal program shown in Figure~\ref{fig:eg}. Clearly, the approach discussed here cannot be directly applied to the program as it not a semialgebraic program. Nevertheless, the technique can be applied to the abstraction of the program shown in Figure~\ref{fig:absRev}. The abstract program is generated
by abstracting the lists by their sizes. 
%
\begin{figure}
\begin{myprogram}
object List \{ \\
\pnl \>    def rev(x: Int) : Int = \{ \\
\pnl \> 	requires(x >= 0) \\
\pnl \> \>      rev0(x, 0)  \\
\pnl \>    \} \\
\pnl \>    ensuring(res => res == x)\\
\\    
\pnl \>    def rev0(x: Int, y: Int) : Int = \{ \\
\pnl \> \>      if(x == 0) y  \\
\pnl \> \>      else rev0(x-1 , y+1) \\
\pnl \>    \} \\ 
\}
\end{myprogram}
\caption{An abstraction of the procedure $rev0$ shown in Figure~\ref{fig:eg}} \label{fig:absRev}
\end{figure}
%
In Figure~\ref{fig:eg}, the variables $x$, $y$ and $res$ represents the 
sizes of the lists $l1$, $l2$ and $res$ respectively.
Invariants of recursive procedures can also be represented as solutions 
of a set of constraints like in the case of loops.
For this example any (useful) invariant should satisfy the following constraints:
%
\begin{align}
& \forall x,res. \; x \ge 0 \wedge I(x,0,res) \Rightarrow res = x \\
& \forall x,y,res. \; x = 0 \Rightarrow I(x,y,res) \\
& \forall x,y,res. \; x \ne 0 \wedge I(x-1,y+1,res) \Rightarrow I(x,y,res)
\end{align}
%
Finding a solution for the above constraints is well within the realm of the approach discussed here (the invariant will be discovered by the approach if a linear template of the form $a.x+b.y+c.res = 0$ is used to model $I(x,y,res)$). The key part here was coming up with the abstract program which requires manual effort.


